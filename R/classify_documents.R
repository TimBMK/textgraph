#' Classify Documents with Walk Terms
#'
#' This function classifies documents based on previously calculated walk terms.
#'
#' @param walk_terms Data frame containing terms generated by `get_rwr_terms()`.
#' @param group_name String; Name of the group variable that specifies the classes
#'   into which the documents will be sorted
#' @param document_tokens Data frame with the documents to be classified.
#'   Expects tokenized data, with a `doc_id` and one token per row in the `tokens_var`.
#' @param tokens_var String; Name of the token variable within the `document_tokens`
#'   data frame (commonly "tokens", "lemma", etc.).
#' @param doc_id String; Name of the `doc_id` variable in `document_tokens`.
#' @param classification_measure String; name of the measure variable to use for
#'   classification, generated by `get_rwr_terms()`. Must be present in `walk_terms`. One of "Score", "ScoreMean",
#'   "ScoreNorm", "ScoreNormMean", "ScoreNormGroup", or "ScoreNormGroupMean". See `get_rwr_terms()` for details.
#' @param classification_cutoff Numerical Cutoff value to filter the `walk_terms`
#'   (optional); NULL to skip. This is useful to apply a stricter cutoff in classification than in
#'   previous steps as all terms below this score will be ignored.
#' @param keep_seed_terms Logical indicator whether to keep seed terms even
#'   if their score is lower than the cutoff (only applies if a cutoff is
#'   specified; default: TRUE).
#' @param seedterm_value Numerical; Fixed value to set for Seed Term Scores before
#'   classification; NULL to skip (optional). Applies to the specified `classification_measure`.
#' @param normalize_scores Method to normalize scores in the documents between 0 and 1.
#'   Options are "doc" (for document-wise normalization), "group" (for group-wise normalization), or NULL to skip (optional).
#' @param cutoff_value Numerical value to set scores below which documents will be set
#'   to 0 for a given group, e.g. documents not scoring higher than 0.2 in a category will have the score set to 0
#'   in that category. This can help with retrieving more distinct documents. NULL to skip (optional).
#' @param cutoff_quantile Logical indicating whether `cutoff_value` specifies
#'   a quantile rather than a fixed value, cutting off values below the value of the specified quantile (default: FALSE).
#' @param cutoff_normalized_scores Logical to apply the cutoff to normalized
#'   scores. Otherwise, normalization is applied after the cutoff (default: TRUE).
#' @param minimum_results Minimum number of results for each group to be
#'   returned, bypassing `cutoff_value` if needed; NULL to skip (optional).
#' @param cut_frequent_group_terms Numerical, "half" or `NULL` to skip. Specifies whether terms appearing in many
#'   groups should be dropped from classification. If a numerical value is supplied, it specifies the maximum number of
#'   categories a term can occur in before getting dropped. If "half", a term gets dropped when in appearing in more than
#'   half of the categories.
#' @param return_walk_terms Logical whether the processed walk terms should
#'   be returned (default: TRUE). Returns the terms actually used for classification, after applying normalization, cutoffs, etc.
#' @param return_unclassified_docs Logical whether the IDs of unclassified
#'   documents should be returned (default: TRUE).
#' @param verbose Logical indicating if the function should report the number
#'   of unclassified documents (default: TRUE).
#'
#' @return A list containing `classified_documents`, and depending on the
#'   parameters, also `walk_terms` and `unclassified_documents`. If
#'   `return_walk_terms` or `return_unclassified_docs` is set to FALSE, the
#'   function returns a single data frame of `classified_documents`.
#'
#' @details
#' This functions classifies documents based on the scores returned by `get_rwr_terms()`. For each group of the `group_name` variable,
#'  it returns a score indicating the connection of the document to this group by summing the scores of each term belonging to each
#'  group within each document. Depending on settings, this summed score can then be normalized over
#'  the group (the most distinctive documents within the whole group score highest) or the document (the most distinctive group in a single
#'  document scores highest) with `normalize_scores`. Additionally, a number of parameters, such as `cutoff_value`, `minimum_results`, and
#'  `cut_frequent_group_terms` are intended to fine-tune the results without re-running the Random Walks with Restart.
#'
#'
#' @export
#'
#' @importFrom dplyr "%>%"
#' @importFrom rlang arg_match
#' @importFrom dplyr filter semi_join left_join summarize distinct mutate slice_max rename select case_when
#' @importFrom tidyr complete
#' @importFrom stringr str_detect
#' @importFrom scales rescale
#' @importFrom stats quantile
#' @importFrom tibble as_tibble
#'
#' @examples
#' # the rwr_terms object in this example is created via get_rwr_terms(). See help(get_rwr_terms)
#'
#' data(de_pol_twitter)
#'
#' classified_documents <- classify_documents(walk_terms = rwr_terms,
#'                                            group_name = "ministry_name",
#'                                            document_tokens = de_pol_twitter,
#'                                            tokens_var = "lemma",
#'                                            doc_id = "doc_id",
#'                                            classification_measure = "ScoreNormMean",
#'                                            classification_cutoff = NULL,
#'                                            keep_seed_terms = TRUE,
#'                                            seedterm_value = NULL,
#'                                            normalize_scores = "group",
#'                                            cutoff_value = NULL,
#'                                            cutoff_quantile = FALSE,
#'                                            cutoff_normalized_scores = TRUE,
#'                                            minimum_results = NULL,
#'                                            cut_frequent_group_terms = NULL,
#'                                            return_walk_terms = TRUE,
#'                                            return_unclassified_docs = TRUE,
#'                                            verbose = TRUE)
classify_documents <- function(
  walk_terms,
  group_name,
  document_tokens,
  tokens_var,
  doc_id,
  classification_measure = c("Score", "ScoreMean",
                             "ScoreNorm", "ScoreNormMean",
                             "ScoreNormGroup", "ScoreNormGroupMean"),
  classification_cutoff = NULL,
  keep_seed_terms = TRUE,
  seedterm_value = NULL,
  normalize_scores = c("doc", "group", NULL),
  cutoff_value = NULL,
  cutoff_quantile = FALSE,
  cutoff_normalized_scores = TRUE,
  minimum_results = NULL,
  cut_frequent_group_terms = c(NULL, numeric(), "half"),
  return_walk_terms = TRUE,
  return_unclassified_docs = TRUE,
  verbose = TRUE
){

  ## Data and Input Checks

  rlang::arg_match(classification_measure)

  rlang::arg_match(normalize_scores)

  if (!is.null(cut_frequent_group_terms)) {
    if (!is.na(cut_frequent_group_terms)) {
      if (!(is.numeric(cut_frequent_group_terms) |
            cut_frequent_group_terms == "half")) {
        stop(
          paste0(
            "cut_frequent_group_terms must be NULL, 'half', or a numeric value, not '",
            cut_frequent_group_terms,
            "'.\n"
          )
        )
      }

    } else {
      stop("cut_frequent_group_terms must be NULL, 'auto', or a numeric value, not NA.\n")

    }
  }

  if (!(classification_measure %in% names(walk_terms))) {
    stop(paste("classification_measure", classification_measure,
               "not present in walk_terms data\n"))
  }

  if (!(doc_id %in% names(document_tokens))) {
    stop(paste("doc_id", doc_id, "not present in document_tokens data\n"))
  }

  ## Data Prep

  ### apply cutoff
  if (!is.null(classification_cutoff)) {
    walk_terms <-
      walk_terms %>% dplyr::filter(!!as.name(classification_measure) >= classification_cutoff |
                                     seed_term == TRUE)
  }

  ### overwrite seedterm values (if desired)
  if (!is.null(seedterm_value)) {
    walk_terms <- walk_terms %>%
      dplyr::mutate(
        !!as.name(classification_measure) := dplyr::case_when(
          seed_term == TRUE ~ seedterm_value,
          .default = !!as.name(classification_measure)
        )
      )
  }

  document_tokens <- document_tokens %>% select(!!as.name(tokens_var), !!as.name(doc_id)) # drop unnecessary variables

  ### calculate means (if necessary) to gain one score for each term in a policy field (rather then one for each seedterm-term connection)
  #### Note that if we calculate the means only now, means are calculated AFTER the initial filtering, and scores will accordingly be higher (all values below the walk_score threshold have already been dropped!)
  if (stringr::str_detect(classification_measure, "Mean")) {
    # if one of the mean scores is set as classification_measure, we simply use that
    classification_terms <- document_tokens %>%
      dplyr::semi_join(walk_terms, # filter for lemmas in the walk terms
                       dplyr::join_by(!!as.name(tokens_var) == NodeNames)) %>%
      dplyr::left_join( # add classification attributes
        walk_terms %>% dplyr::distinct(NodeNames,
                                       !!as.name(classification_measure),
                                       !!as.name(group_name)),
        dplyr::join_by(!!as.name(tokens_var) == NodeNames),
        relationship = "many-to-many"
      )  # multi-matches for a) terms in multiple docs, b) terms in multiple groups
  } else {
    # else, we need to calculate the mean for each term within a policy field first, in order to handle duplicates from different seed terms
    classification_terms <- document_tokens %>%
      dplyr::semi_join(walk_terms, # filter for token var in the walk terms
                       dplyr::join_by(!!as.name(tokens_var) == NodeNames)) %>%
      dplyr::left_join(
        walk_terms %>%
          dplyr::summarise(
            !!as.name(classification_measure) := mean(!!as.name(classification_measure)),
            .by = c(NodeNames, !!as.name(group_name))
          ),
        dplyr::join_by(!!as.name(tokens_var) == NodeNames),
        # add classification attributes
        relationship = "many-to-many"
      )
  }

  ## cut frequent policy terms
  if (!is.null(cut_frequent_group_terms)) {
    if (cut_frequent_group_terms == "half") {
      classification_terms <- classification_terms %>%
        filter(!!as.name(tokens_var) %in% (classification_terms %>%
                                             count(!!as.name(tokens_var), !!as.name(group_name)) %>%
                                             count(!!as.name(tokens_var)) %>%
                                             filter(n <= (distinct(classification_terms,
                                                                   !!as.name(group_name)) %>%
                                                            nrow() / 2)) %>%
                                             pull(!!as.name(tokens_var))))
    } else {
      classification_terms <- classification_terms %>%
        filter(!!as.name(tokens_var) %in% (classification_terms %>%
                                             count(!!as.name(tokens_var), !!as.name(group_name)) %>%
                                             count(!!as.name(tokens_var)) %>%
                                             filter(n <= cut_frequent_group_terms) %>%
                                             pull(!!as.name(tokens_var))))
    }
  }


  ## classify

  classified_documents <- classification_terms %>%
    dplyr::summarize(score = sum(!!as.name(classification_measure)),
                     .by = c(!!as.name(doc_id), !!as.name(group_name))) %>% # sum policy scores by field and document
    tidyr::complete(!!as.name(doc_id),!!as.name(group_name),
                    fill = list(score = 0))


  ### apply cutoff before normalization
  if (!cutoff_normalized_scores & !is.null(cutoff_value)) { # set scores to 0 for lower quantiles

    if (!is.null(minimum_results)) { # preserve original values for the minimum results
      top_values <- classified_documents %>%
        dplyr::slice_max(score, n = minimum_results,
                         by = !!as.name(group_name)) %>%
        dplyr::rename(top_value = score) %>%
        dplyr::select({{doc_id}}, {{group_name}}, top_value)
    }

    if (cutoff_quantile) {

      quantile <- stats::quantile(classified_documents$score,
                                  cutoff_value)[[1]]
      classified_documents <- classified_documents %>%
        dplyr::mutate(score = dplyr::case_when(score < quantile ~ 0,
                                               .default = score))

      if (verbose) {
        cat(paste0("Setting score-values below ",
                   quantile, " (", cutoff_value,
                   " quantile) to 0. This step is applied before normalization.\n"))
      }
    } else {
      classified_documents <- classified_documents %>%
        dplyr::mutate(score = dplyr::case_when(score < cutoff_value ~ 0,
                                               .default = score))
      if (verbose) {
        cat(paste("Setting score-values below",
                  cutoff_value,
                  "to 0. This step is applied before normalization.\n"))
      }
    }

    if (!is.null(minimum_results)) {
      classified_documents <- classified_documents %>%
        dplyr::left_join(top_values, by = c(doc_id, group_name)) %>%
        dplyr::mutate(top_value = dplyr::case_when( # replace NAs from matching with 0s
          is.na(top_value) ~ 0, .default = top_value)) %>%
        dplyr::mutate(score = dplyr::case_when( # and replace 0 values with top values where the number of scores > 0 is below the minimum
          sum(score > 0) < minimum_results ~ top_value,
          .default = score), .by = !!as.name(group_name)) %>%
        dplyr::select(!top_value)

      if (verbose) {
        cat(paste("A minimum of", minimum_results, "results per", group_name,
                  "is returned. This may overwrite the cutoff_value.\n"))
      }
    }

  }

  if (!is.null(normalize_scores)) {
    if (normalize_scores == "doc") {
      # rescale the scores in documents
      classified_documents <- classified_documents %>%
        dplyr::mutate(
          score_norm = scales::rescale(score, to = c(0, 1)),
          .by = !!as.name(doc_id)
        )
    }
    if (normalize_scores == "group") {
      # rescale the scores in groups
      classified_documents <- classified_documents %>%
        dplyr::mutate(
          score_norm = scales::rescale(score, to = c(0, 1)),
          .by = !!as.name(group_name)
        )
    }

    ### set the normalized score 0 to when the score is 0. This prevents documents with 0 in all groups to show as 0.5 in the score_norm
    classified_documents <- classified_documents %>%
      dplyr::mutate(score_norm = dplyr::case_when(score == 0 ~ 0,
                                                  .default = score_norm))
  }

  ### apply cutoff after normalization
  if (cutoff_normalized_scores & !is.null(cutoff_value)) { # set scores to 0 for lower quantiles

    if (!is.null(minimum_results)) { # preserve original values for the minimum results
      top_values <- classified_documents %>%
        dplyr::slice_max(score_norm, n = minimum_results,
                         by = !!as.name(group_name)) %>%
        dplyr::rename(top_value = score_norm) %>%
        dplyr::select({{doc_id}}, {{group_name}}, top_value)
    }

    if (cutoff_quantile){

      quantile <- stats::quantile(classified_documents$score_norm,
                                  cutoff_value)[[1]]
      classified_documents <- classified_documents %>%
        dplyr::mutate(score_norm = dplyr::case_when(score_norm < quantile ~ 0,
                                                    .default = score_norm))

      if (verbose) {
        cat(paste0("Setting normalized score-values below ",
                   quantile, " (", cutoff_value,
                   " quantile) to 0. Non-normalized scores are set to 0 in accordance.\n"))
      }
    } else {
      classified_documents <- classified_documents %>%
        dplyr::mutate(score_norm = dplyr::case_when(score_norm < cutoff_value ~ 0,
                                                    .default = score_norm))
      if (verbose) {
        cat(paste("Setting normalized score-values below",
                  cutoff_value,
                  "to 0. Non-normalized scores are set to 0 in accordance.\n"))
      }
    }

    ### set non-normalized score to 0 where score_norm is 0
    classified_documents <- classified_documents %>%
      dplyr::mutate(score = case_when(score_norm == 0 ~ 0, .default = score))

    if (!is.null(minimum_results)) {
      classified_documents <- classified_documents %>%
        dplyr::left_join(top_values, by = c(doc_id, group_name)) %>%
        dplyr::mutate(top_value = dplyr::case_when( # replace NAs from matching with 0s
          is.na(top_value) ~ 0, .default = top_value)) %>%
        dplyr::mutate(score_norm = dplyr::case_when( # and replace 0 values with top values where the number of scores > 0 is below the minimum
          sum(score_norm > 0) < minimum_results ~ top_value,
          .default = score_norm), .by = !!as.name(group_name)) %>%
        dplyr::select(!top_value)

      if (verbose) {
        cat(paste("A minimum of", minimum_results, "results per", group_name,
                  "is returned. This may overwrite the cutoff_value.\n"))
      }
    }

  }

  ## report unclassified documents
  if (verbose | return_unclassified_docs) {
    unclassified_documents <- document_tokens %>%
      dplyr::anti_join(classified_documents,
                       by = dplyr::join_by(!!as.name(doc_id))) %>%
      dplyr::distinct(!!as.name(doc_id))

    if (verbose) {
      unclassified <- unclassified_documents %>% nrow()
      total <- document_tokens %>% distinct(!!as.name(doc_id)) %>% nrow()
      cat(paste(unclassified,
                "out of",
                total,
                "documents could not be classified",
                paste0("(", scales::percent(unclassified/total,
                                            accuracy = 0.01), ")"),
                "\n"))
    }
  }

  ## return the result
  if (return_walk_terms | return_unclassified_docs) {

    out <- list()

    out$classified_documents <- classified_documents

    if (return_walk_terms) { # return the processed and formatted walk_terms
      classification_terms_out <- classification_terms %>%
        dplyr::distinct(!!as.name(tokens_var),
                        !!as.name(group_name),
                        !!as.name(classification_measure))

      if (stringr::str_detect(classification_measure, "Mean")) {
        classification_terms_out <- classification_terms_out %>%
          dplyr::left_join(walk_terms %>% # add seed_term indicator
                             dplyr::distinct(!!as.name(group_name),
                                             NodeNames, seed_term),
                           by = dplyr::join_by(!!as.name(group_name),
                                               !!as.name(tokens_var) == NodeNames))
      } else { # if means were calculated during the process, we report the unprocessed values
        classification_terms_out <- classification_terms_out %>%
          dplyr::left_join(walk_terms %>%
                             dplyr::distinct(!!as.name(group_name),
                                             NodeNames, seed_term,
                                             !!as.name(classification_measure)) %>%
                             rename_with(~ paste0(classification_measure,
                                                  "_unprocessed"),
                                         all_of(classification_measure)),
                           by = dplyr::join_by(!!as.name(group_name),
                                               !!as.name(tokens_var) == NodeNames))
      }

      out$walk_terms <- classification_terms_out %>%
        dplyr::arrange(!!as.name(group_name),
                       dplyr::desc(!!as.name(classification_measure))) %>%
        dplyr::select(!!as.name(tokens_var),
                      !!as.name(group_name),
                      seed_term,
                      !!as.name(classification_measure),
                      everything())

    }

    if (return_unclassified_docs) {
      out$unclassified_documents <- unclassified_documents
    }

    return(out)

  } else {
    return(classified_documents)
  }

}
